{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"../dataset/018.감성대화/Training_221115_add/감성대화말뭉치(최종데이터)_Training.json\"\n",
    "val_data_dir = \"../dataset/018.감성대화/Validation_221115_add/감성대화말뭉치(최종데이터)_Validation.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>talk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51628</td>\n",
       "      <td>51628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1919</td>\n",
       "      <td>51628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>{'persona-id': 'Pro_05368', 'persona': {'perso...</td>\n",
       "      <td>{'id': {'profile-id': 'Pro_05349', 'talk-id': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  profile  \\\n",
       "count                                               51628   \n",
       "unique                                               1919   \n",
       "top     {'persona-id': 'Pro_05368', 'persona': {'perso...   \n",
       "freq                                                   97   \n",
       "\n",
       "                                                     talk  \n",
       "count                                               51628  \n",
       "unique                                              51628  \n",
       "top     {'id': {'profile-id': 'Pro_05349', 'talk-id': ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_json(train_data_dir)\n",
    "val_data = pd.read_json(val_data_dir)\n",
    "\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "sentiments = \"\"\"분노 슬픔 불안 상처 당황 기쁨\n",
    "툴툴대는 실망한 두려운 질투하는 고립된 감사하는\n",
    "좌절한 비통한 스트레스_받는 배신당한 남의_시선_의식하는 사랑하는\n",
    "짜증나는 후회되는 취약한 고립된 외로운 편안한\n",
    "방어적인 우울한 혼란스러운 충격_받은 열등감 만족스러운\n",
    "악의적인 마비된 당혹스러운 불우한 죄책감 흥분되는\n",
    "안달하는 염세적인 회의적인 희생된 부끄러운 느긋한\n",
    "구역질_나는 눈물이_나는 걱정스러운 억울한 혐오스러운 안도하는\n",
    "노여워하는 낙담한 조심스러운 괴로워하는 한심한 신이_난\n",
    "성가신 환멸을_느끼는 초조한 버려진 혼란스러운 자신하는\"\"\"\n",
    "\n",
    "sentiments = sentiments.replace(\"\\n\", \" \").split(\" \")\n",
    "\n",
    "print(len(sentiments))\n",
    "\n",
    "labeltoindex = [[sentiments[i+6*j] for j in range(10)] for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoi(label):\n",
    "    for i, labels in enumerate(labeltoindex):\n",
    "        if label in labels:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def itos(index):\n",
    "    return labeltoindex[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi(\"분노\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': {'profile-id': 'Pro_03694', 'talk-id': 'Pro_03694_00004'},\n",
       "  'content': {'HS01': '나 빼고 전부 결혼했어. 모임에 나갔더니 나만 혼자야.',\n",
       "   'SS01': '혼자만 싱글이라 속상하시군요. 이럴 때 상황을 극복할 좋은 방법이 있을까요?',\n",
       "   'HS02': '나도 빨리 좋은 여자를 만나고 싶어. 앞으로는 소개팅 거절하지 않고 만나볼 거야. 언젠가는 좋은 인연을 만날 수 있겠지.',\n",
       "   'SS02': '소개팅하다 보면 좋은 인연을 만나게 되겠군요.',\n",
       "   'HS03': '',\n",
       "   'SS03': ''}},\n",
       " {'persona-id': 'Pro_03694',\n",
       "  'persona': {'persona-id': 'A02_G01_C01',\n",
       "   'human': ['A02', 'G01'],\n",
       "   'computer': ['C01']},\n",
       "  'emotion': {'emotion-id': 'S05_D02_E43',\n",
       "   'type': 'E43',\n",
       "   'situation': ['S05', 'D02']}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 120\n",
    "train_data.talk[index], train_data.profile[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label.txt\", \"w\") as f:\n",
    "    f.writelines(\"\\n\".join([\" \".join(labels) for labels in labeltoindex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['분노', '툴툴대는', '좌절한', '짜증나는', '방어적인', '악의적인', '안달하는', '구역질_나는', '노여워하는', '성가신'], ['슬픔', '실망한', '비통한', '후회되는', '우울한', '마비된', '염세적인', '눈물이_나는', '낙담한', '환멸을_느끼는'], ['불안', '두려운', '스트레스_받는', '취약한', '혼란스러운', '당혹스러운', '회의적인', '걱정스러운', '조심스러운', '초조한'], ['상처', '질투하는', '배신당한', '고립된', '충격_받은', '불우한', '희생된', '억울한', '괴로워하는', '버려진'], ['당황', '고립된', '남의_시선_의식하는', '외로운', '열등감', '죄책감', '부끄러운', '혐오스러운', '한심한', '혼란스러운'], ['기쁨', '감사하는', '사랑하는', '편안한', '만족스러운', '흥분되는', '느긋한', '안도하는', '신이_난', '자신하는']]\n"
     ]
    }
   ],
   "source": [
    "def load_label():\n",
    "    with open(\"label.txt\", \"r\") as f:\n",
    "        loaded = f.readlines() \n",
    "    processed = [l.replace(\"\\n\", \"\").split(\" \") for l in loaded]\n",
    "    return processed\n",
    "        \n",
    "\n",
    "load_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, data, label, max_token_len):\n",
    "        self.x = data\n",
    "        self.y = label\n",
    "        self.max_token_len = max_token_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        x = tokenizer.encode(x)\n",
    "        if len(x) > self.max_token_len:\n",
    "            x = x[:self.max_token_len]\n",
    "        x = torch.tensor(x, device=torch.device(\"cuda\"))\n",
    "        x = torch.nn.functional.pad(x ,pad=(1, self.max_token_len-x.shape[0]-1),value = 1)\n",
    "        y = self.y[index]\n",
    "        y = torch.tensor(y, device=torch.device(\"cuda\"))\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for i, (profile, talk) in enumerate(zip(train_data.profile, train_data.talk)):\n",
    "    text = list(talk[\"content\"].values())[0]\n",
    "    label = int(profile[\"emotion\"][\"type\"][1]) - 1\n",
    "    \n",
    "    texts.append(text)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token_len = 50\n",
    "dataset = SentimentDataset(texts, labels, max_token_len=max_token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   1,    2, 3803, 7086, 3466, 5002, 5002, 1363, 7096, 3282, 5591,  258,\n",
       "         5112, 5330, 1406, 5782,   54,    3,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1], device='cuda:0'),\n",
       " tensor(0, device='cuda:0'))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "\n",
    "def train(model,train_data):\n",
    "    model.train()\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(),lr = 0.005)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "   \n",
    "    epochs = 30\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        t_loss = 0\n",
    "        for x,y in tqdm.tqdm(train_data):        \n",
    "            out = model(x)\n",
    "            loss = loss_fn(out,y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            t_loss += loss.detach().item()\n",
    "\n",
    "        print(f\"Epoch : {epoch + 1} / {epochs} \\t Train  Loss : {t_loss/len(train_data) : .3f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 30 \t Train  Loss :  1.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 / 30 \t Train  Loss :  1.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 / 30 \t Train  Loss :  1.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 / 30 \t Train  Loss :  1.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 / 30 \t Train  Loss :  1.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6 / 30 \t Train  Loss :  1.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7 / 30 \t Train  Loss :  1.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8 / 30 \t Train  Loss :  1.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:21<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9 / 30 \t Train  Loss :  1.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 18.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 / 30 \t Train  Loss :  1.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 18.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11 / 30 \t Train  Loss :  1.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12 / 30 \t Train  Loss :  1.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13 / 30 \t Train  Loss :  1.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14 / 30 \t Train  Loss :  1.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15 / 30 \t Train  Loss :  1.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16 / 30 \t Train  Loss :  1.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17 / 30 \t Train  Loss :  1.360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18 / 30 \t Train  Loss :  1.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19 / 30 \t Train  Loss :  1.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20 / 30 \t Train  Loss :  1.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 17.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 21 / 30 \t Train  Loss :  1.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 22 / 30 \t Train  Loss :  1.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 23 / 30 \t Train  Loss :  1.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 24 / 30 \t Train  Loss :  1.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 25 / 30 \t Train  Loss :  1.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 26 / 30 \t Train  Loss :  1.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 27 / 30 \t Train  Loss :  1.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:23<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 28 / 30 \t Train  Loss :  1.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 29 / 30 \t Train  Loss :  1.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404/404 [00:22<00:00, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 30 / 30 \t Train  Loss :  1.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from model import SentimentAnalysis\n",
    "\n",
    "model = SentimentAnalysis(tokenizer.vocab_size, 50, n_filters=5, filter_sizes=[2, 3, 4], pool_size=1, dropout=0.2, hidden_size=100, num_classes=6).to(\"cuda\")\n",
    "\n",
    "train(model, train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(command):\n",
    "    x = tokenizer.encode(command)\n",
    "    if len(x) > max_token_len:\n",
    "        x = x[:max_token_len]\n",
    "    x = torch.tensor(x, device=torch.device(\"cuda\"))\n",
    "    x = torch.nn.functional.pad(x ,pad=(1, max_token_len-x.shape[0]-1),value = 1)\n",
    "    x = x.unsqueeze(0)\n",
    "    \n",
    "    pred = model(x)\n",
    "    \n",
    "    return torch.argmax(pred, dim=1)[0].detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['기쁨', '감사하는', '사랑하는', '편안한', '만족스러운', '흥분되는', '느긋한', '안도하는', '신이_난', '자신하는']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos(generate(\"안녕안녕 반가워!\").tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['기쁨', '감사하는', '사랑하는', '편안한', '만족스러운', '흥분되는', '느긋한', '안도하는', '신이_난', '자신하는']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos(generate(\"이제 직접 실행시켜서 확인해봅시다!\").tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['불안',\n",
       " '두려운',\n",
       " '스트레스_받는',\n",
       " '취약한',\n",
       " '혼란스러운',\n",
       " '당혹스러운',\n",
       " '회의적인',\n",
       " '걱정스러운',\n",
       " '조심스러운',\n",
       " '초조한']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
